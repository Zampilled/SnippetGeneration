from tqdm import tqdm
from transformers import AutoModelForCausalLM, AutoTokenizer


class SnippetModel:
    """
        Class to handle a text generation model using tokenization and prediction steps.
    """

    def __init__(self, name, device):
        """
        :param name: The name or path of the pre-trained model to load. This should be compatible with Hugging Face's model repository.
        :param device: The device to run the model on, typically 'cpu' or 'cuda' for GPU acceleration.

        """
        self.data = None
        self.device = device
        self.tokenizer = AutoTokenizer.from_pretrained(name)
        self.model = AutoModelForCausalLM.from_pretrained(name).to(device)

    def insert_data(self, data):
        """
        Inserts data into the model for further processing.
        :param data: The data to be copied and inserted. Should be a collection or dict that supports the copy() method.
        :return: None
        """
        self.data = data.copy()

    def tokenize_one(self, row):
        """
        tokenizes one string and returns it as a tensor.
        :param row: The input string to be tokenized.
        :return: The tokenized representation of the input string as a tensor, transferred to the specified device.
        """
        return self.tokenizer.encode(row, return_tensors="pt").to(self.device)

    def tokenize_data(self):
        """
        Tokenizes the processed data in the DataFrame.
        :return: None
        """
        tqdm.pandas()
        self.data["tokenized"] = self.data["processed"].progress_apply(self.tokenize_one)

    def run_model_once(self, row):
        """
        Generates one output of the model.
        :param row: Input data for the model. Typically, this is the data that will be passed through the model for processing and generation.
        :return: A list of generated sequences based on the input data. Each sequence is a potential output generated by the model with a maximum length of 1000 tokens.
        """
        return self.model.generate(row, max_length=1000, do_sample=True, num_return_sequences=3)

    def run_model(self):
        """
        This method applies the run_model_once function to each element in the 'tokenized' column
        of the 'data' DataFrame, and stores the result in the 'output' column. It utilizes the
        tqdm library to display a progress bar for the operation.

        :return: None
        """
        tqdm.pandas()
        self.data["output"] = self.data["tokenized"].progress_apply(self.run_model_once)

    def decode_one(self, row):
        """
        Decodes the tokenized output
        :param row: A list-like structure where the first element is expected to be a tokenized sequence.
        :return: Decoded string obtained from the first element in 'row', with special tokens skipped and tokenization spaces not cleaned up.
        """
        return self.tokenizer.decode(row[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)

    def decode_data(self):
        """
        Decodes the data in the 'output' column of the dataframe and stores the result in the 'predictions' column.
        :return: None
        """
        tqdm.pandas()
        self.data["predictions"] = self.data["output"].progress_apply(self.decode_one)

    def get_output(self):
        """
        :return: The 'data' attribute.
        """
        return self.data
